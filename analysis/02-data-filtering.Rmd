---
title: "DATA FILTERING"
author: "Andree Valle Campos"
date: '`r Sys.Date()`'
output: 
  html_document:
#  pdf_document:
#  html_notebook:
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
    code_folding: "hide"
#    number_sections: TRUE
#    df_print: kable
#    fig_caption: true
#  documentclass: report
bibliography: SeroMarker.bib
csl: american-medical-association.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, # CHANGE TO FALSE IN PDF_DOCUMENTS
                      warning = FALSE) #fig.path = "02-"
knitr::opts_knit$set(root.dir = '../.') #gsub("/analysis","",getwd())
#getwd()
options(width = 110) # CHANGE TO DEFAULT in PDF
# FOR PDF CHANGE: html_document, toc_float, number_sections, echo, width
# FOR PDF add new page USE: four \newpage BEFORE #SETUP #APPENDIX #COMPUTER.env #REFERENCES
```

# Setup 

This report is writen in **R** [@R] within a `Rmarkdown` [@rmarkdown] notebook using the `RStudio` [@rstudio] IDE software, and employing the `knitr` [@knitr] and `Hmisc` [@Hmisc] packages for the `html` setup.

This dynamic document integrates **text**, **code** and **results**.

```{r setup0, results='hide', message=FALSE, eval=TRUE}
require(Hmisc)
#require(plotly)
#options(#grType='plotly',  # for certain graphics functions
#        width = 110) # to expand the limits of CONSOLE output
mu <- markupSpecs$html   # markupSpecs is in Hmisc

# The following hidden command (<code>r mu$widescreen()</code>), causes the html notebook to use an entire wide screen.
#mu$widescreen()
```
`r mu$widescreen()`

# Summary

**OBJECTIVE:**

* Principal: 
    - Standardize the OD~450nm~ values across ELISA plates by the estimation of the Antibody Units of each unknown sample.

* Secondary:
    - Implement a [reproducible workflow](https://www.ncbi.nlm.nih.gov/pubmed/26776185) for standardization of ELISA plates from a template matrix.


# Introduction

This is an R implementation of a pipeline for the standardization of ELISA plates directly from a template matrix.


# Dependencies

The required R packages for this analysis are:

+ XLConnect [@XLConnect]
+ drc [@Ritz2015]

```{r, results='hide', message=FALSE}
##essential
library(XLConnect)    # load EXCEL workbooks
library(drc)          # Dose-Response modeling
##accesory
library("DiagrammeR") # method Flowchart
library("knitr")      # To display nice tables
library("tidyverse")
#ggplot2, tibble, tidyr, readr, purr, dplyyr
##extra
library("Rmisc")      # multiplot ggplots
library("haven")      # import STATA df
library("readxl")     # import EXCEL df
library("forcats")    # factor vectors
library("stringr")    # strings
library("viridis")    # color visualization
```

# read .Rds
```{r}
std.raw <- readRDS("data/01-output-raw.rds")
std.par <- readRDS("data/01-parameters.rds")
```

***

# Results

## DB typo corrections

After showing the missing of **02** samples in the Templates, typos were identified and the corresponding modifications were made following Reproducible Reseach paradigms, i.e. avoiding any editing on the original DB.

This correction introduced the following samples:

- **ZG009-3**, by changing *ZG009-1* in plate **N17**, and

```{r}
#str(std.raw)
std.raw$ID <- as.character(std.raw$ID)

std.raw[std.raw$ID=="ZG009-1",]
#std.raw[std.raw$ID=="ZG009-1" & std.raw$Plate=="N17",]
std.raw[std.raw$ID=="ZG009-1" & std.raw$Plate=="N17",2] <- rep("ZG009-3",2)
#std.raw[std.raw$ID=="ZG009-1",]
std.raw[std.raw$ID=="ZG009-3",]
```

- **NN068-2**, by changing *NN082-5* in plate **N33**.

```{r}
std.raw[std.raw$ID=="NN082-5",]
#std.raw[std.raw$ID=="NN082-5" & std.raw$Plate=="N33",]
std.raw[std.raw$ID=="NN082-5" & std.raw$Plate=="N33",2] <- rep("NN068-2",2)
std.raw[std.raw$ID=="NN068-2",]
#std.raw[std.raw$ID=="NN082-5",]

std.raw$ID <- as.factor(std.raw$ID)
#str(std.raw)
```

As expected, this reduced the number of duplicates.

## ALL

```{r}
## total de ID evaluados
mue <- length(levels(as.factor(std.raw$ID))) # TOTAL MUESTRAS EVALUADAS
## total ESPERADO + REPLICAS
rep <- dim(std.raw)[1] # TOTAL INICIAL
## total ESPERADO de ID x2 SPECIES-REPLICATES (uno de P.VIVAX y uno de P.FALCIPARUM)
esp <- 2*length(levels(as.factor(std.raw$ID))) # TOTAL ESPERADO
## total de ID REPETIDOS (corridos por duplicado o triplicado en nuevos PLATES) y que se deben retirar
repet <- rep - esp
```

The total amount of evaluated samples is **`r mue`**. However, due to the presence of replicates among Templates, the initial number of reported reads with both `mean.OD` and estimated `Ab.unit` goes up to **`r rep`**.

If each sample have 02 reads, 01 per specie, then the **total expected** amount of samples is **`r esp`**. The rest are replicates (**`r repet`**).

Here is the total amount of evaluated samples in both Pv/Pf plates of each Template file:

```{r}
## total de muestras por TEMPLATE (P.VIVAX igual a P.FALCIPARUM)
table(std.raw[std.raw$Specie=="Pviv",]$Plate)
```

- 04 Templates with lower samples than expected:
    + N12 (n=39), N18 (n=36), N23 (n=10), N41 (n=18).

- 01 Template with more samples than expected:
    + N15 (n=41)
        - **ZG181-1** sampled against **Pviv** plate only
        - **ZG182-1** sampled against **Pfal** plate only.
    + Both generated NaNs at the end.
    + Further dicussion at the end of the next section.

## NA

The total amount of samples with **unestimated `Ab.unit` goes up to `r sum(is.na(std.raw$Ab.unit))`**:
```{r}
## muestras con Ab.units NO estimadas
table(std.raw[is.na(std.raw$Ab.unit)==TRUE,]$Plate)

## MOTIVO: above plate-specific model upper limit or below its lower limit
#sum(is.na(std.raw$Ab.unit))
std.nan <- std.raw[is.na(std.raw$Ab.unit)==TRUE,]
#std.nan
```

**NOTE:** Only **03 samples** with NaN in both reads. Sample **ZG177-4** will be further evaluated in the `Duplicates` section of [UNBIASED selection](#unbiased-selection):
```{r}
NaN_2 <- names(which(table(factor(std.raw[is.na(std.raw$Ab.unit)==TRUE,]$ID))==2))
NaN_2

NaN_2_MAT <- data.frame()
for (i in 1:length(NaN_2)) {
  NaN_2_MAT <- rbind(NaN_2_MAT,std.raw[std.raw$ID==NaN_2[i],])
}

#NaN_2_MAT[-c(7:10),]
NaN_2_MAT[NaN_2_MAT$ID!="ZG177-4",]

```

On the other hand, the total amount of samples with **`mean.OD` with `NA` is `r sum(is.na(std.raw$mean.OD))`**:
```{r}
## muestras con OD con valor NA?
#sum(is.na(std.raw$mean.OD))
std.raw[is.na(std.raw$mean.OD)==TRUE,]
```

Both samples belong to **N15**. The problem here was that in this Template, one sample was evaluates in the Pf plate, and the other one in the Pv plate: 

- **ZG181-1**, since it is a replicate, it have reads for both species.
```{r}
std.raw[std.raw$ID=="ZG181-1",]
```

- However, **ZG182-1** was only evaluated once, for one ELISA plate and for one specie.
```{r}
std.raw[std.raw$ID=="ZG182-1",]
```

## REPLICATES

From the **total expected** samples, we calculate that the total amount of reads in excess that came from replicates (duplicates or triplicates) among Templates goes up to **`r repet`**.

```{r}
## FRECUENCIA por ID
Ab_freq <- data.frame(table(as.factor(std.raw$ID)))

## total de ID con mas de una replica por especie
#dim(Ab_freq[Ab_freq$Freq>2,])[1]

## ID con duplicado
#dim(Ab_freq[Ab_freq$Freq==4,])[1]

## ID con triplicado?
#dim(Ab_freq[Ab_freq$Freq==6,])[1]

## RESULTADO DE SUBTRACCION DE REPLICAS
## ID con duplicado + ## ID con triplicado
subtra <- 2*(sum(Ab_freq$Freq==4)) + 4*(sum(Ab_freq$Freq==6)) # cantidades a subtraer
#subtra

## LA SUBTRACCION DE REPLICAS es IGUAL al total de ID A RETIRAR
#subtra == repet # 194
```

The total amount of samples with **duplicated** reads is **`r dim(Ab_freq[Ab_freq$Freq==4,])[1]`** and with **triplicated** reads is **`r dim(Ab_freq[Ab_freq$Freq==6,])[1]`**.

```{r}
summary(factor(Ab_freq$Freq))
```

### Triplicates

Listado de muestras **triplicadas** (n=`r dim(Ab_freq[Ab_freq$Freq==6,])[1]`):
```{r}
## LISTADO de muestras TRIPLICADAS
triplOD <- Ab_freq[Ab_freq$Freq==6,]$Var1

triplMAT <- data.frame()
for (i in 1:length(triplOD)) {
  triplMAT <- rbind(triplMAT,std.raw[std.raw$ID==triplOD[i],])
}

as.character(triplOD)

dim(triplMAT)
#head(triplMAT,12)
summary(triplMAT[,-c(3,6)])
```

### Duplicates

Listado de muestras **duplicadas** (n=`r dim(Ab_freq[Ab_freq$Freq==4,])[1]`):
```{r}
## LISTADO de muestras DUPLICADAS
dupliOD <- Ab_freq[Ab_freq$Freq==4,]$Var1

dupliMAT <- data.frame()
for (i in 1:length(dupliOD)) {
  dupliMAT <- rbind(dupliMAT,std.raw[std.raw$ID==dupliOD[i],])
}

as.character(dupliOD)

dim(dupliMAT)
#head(dupliMAT, 12)
summary(dupliMAT[,-c(3,6)])
```

## UNBIASED selection

Unbiased selection criteria of Ab.units estimate among replicated reads of per sample:

+ **NOTE:** This assumes that no dilution to the original evaluated sample has been performed.
    + For triplicates, the closest value to the mean among replicates was selected
    + Reads with mean.OD with a %CV higher than 20% were rejected
    + For duplicates, the replicate with lower %CV was preferred.
    + If a selection was not acomplished, the last read performed was preferred.

This criteria have been implemented in a **function** called `Unbiased()`:

```{r}
#### FUNCION PARA LA APLICACION DEL CRITERIO
Unbiased <- function(repliMAT) {
  # LOOP: closest value to the mean
  z <- NULL
  # for each ID with replicates
  for(i in 1:length(levels(repliMAT$ID))){
    # for each Specie
    for (j in 1:length(levels(repliMAT$Specie))) {
      # extrae Ab.unit y %CV para cada especie
      x <- repliMAT[repliMAT$ID==levels(repliMAT$ID)[i] & 
                    repliMAT$Specie==levels(repliMAT$Specie)[j], c(4,8)]
      if (any(x$cv.OD>=20, na.rm = TRUE)) {
        # lecturas con %CV>=20% seran descartadas (independiente de OD>0.25)
        x <- x[-which(x$cv.OD>=20),]
      }
      y <- mean(x$Ab.unit, na.rm = TRUE)
      # elije cual de los valores es igual a la menor diferencia con la media aritmetica
      a <- x[which(min(abs(x$Ab.unit - y), na.rm = TRUE)==abs(x$Ab.unit - y)),]
    
      if (dim(a)[1]>1) {
        # para 2 lecturas, elegir la que tenga menor %CV
        a <- a[which(a$cv.OD==min(a$cv.OD, na.rm = TRUE)),]$Ab.unit
        if (length(a)>1) {
          # si no hay diferencias por %CV, entonces optar por la ultima lectura
          a <- a[2] 
        }
      } else {
        # si la dimension es igual a 1, entonces extraer las Ab.units
        a <- a$Ab.unit
      }
    
      z <- c(z,a)
    }
  }
  # LOOP para asignar eleccion a una tabla
  w <- NULL
  for(i in 1:length(z)){
    # evita IDENTIDAD entre Ab.Units de distintas muestras
    # seleccion por bloques
    v <- repliMAT[repliMAT$ID==levels(repliMAT$ID)[ceiling(i/2)],] 
    w <- rbind(w,subset(v, Ab.unit==z[i])) 
  }
  # output
  return(w)
}
####
```


The results will be shown as follows:

- First, the number of reads per samples: equal to 06 for triplicates and 04 for duplicates. 

- After criteria execution, the same table is presented with only 02 remaining reads per sample, 01 per specie.

- Finally, a table is presented with the samples and selected reads.

### Triplicates
```{r}
triplMAT$ID <- factor(triplMAT$ID)
table(triplMAT$ID)
#triplMAT[triplMAT$ID==levels(triplMAT$ID)[1],]

w <- Unbiased(triplMAT)
# output
table(w$ID)
dim(w)
summary(w[,-c(3,6)])
#w

triplNEW <- w

## CHECK
#length(z) == dim(w)[1]
#sum(table(w$ID)!=2)
```

### Duplicates

Sample **ZG177-4** is initially removed due to both reads for **Pfal** with **NaN**. After criteria execution, the selected replicated read for **Pviv** is going to be added.

```{r}
dupliMAT$ID <- factor(dupliMAT$ID)
#table(dupliMAT$ID)
extra <- dupliMAT[dupliMAT$ID=="ZG177-4",]
extra
dupliMAT <- dupliMAT[dupliMAT$ID!="ZG177-4",] # RETIRAR debido a que tiene DOS lecturas con NAN para FALCIPARUM
dupliMAT$ID <- factor(dupliMAT$ID)
table(dupliMAT$ID)
#dupliMAT[dupliMAT$ID==levels(dupliMAT$ID)[1],]

w <- Unbiased(dupliMAT)
# output
table(w$ID)
dim(w)
summary(w[,-c(3,6)])
#w
dupliNEW <- w

## CHECK:
#length(z) == dim(w)[1]
#sum(table(w$ID)!=2)
#

# ADD EXTRA "ZG177-4" only VIVAX
dupliNEW <- rbind(dupliNEW,extra[4,]) # +1
#dim(std.raw)

```

## FILTERING

- Aim:
    + Retrieve of all replicated reads: triplicates, duplicates and NaN.
    + Addition of selected reads among triplicates and duplicates.
    + Visualization of mean.OD-Ab.unit non-linearity and whole %CV before and after the procedure

### Plot previous to filtering

```{r pre-filter, fig.align='center', fig.height=3, fig.width=9}
summary(std.raw[,-c(1:2)])
par(mfrow=c(1,3))
### NON LINEAR RELATIONSHIP
plot(mean.OD ~ Ab.unit,std.raw,
     ylim = c(0,1.5), 
     xlim = c(0,5e3),
     main="OD-Ab.unit Non-linearity", pch=4) 
with(subset(std.raw, Specie=="Pviv"), 
     points(Ab.unit, mean.OD, col="blue", pch=4))
with(subset(std.raw, Specie=="Pfal"), 
     points(Ab.unit, mean.OD, col="red", pch=4))
legend("topright", c("P.vivax","P.falcip"), #, "C+/-", "blank"
       col = c( "blue", "red"), #, "black", "black"
       pch = c(4, 4), #, NA, NA #lwd= c(1,1),
       #lty = c(NA, NA), #, 3, 2
       cex = 0.8,
       inset = .01#, merge = TRUE
)
plot(mean.OD ~ log(Ab.unit),std.raw,
     ylim = c(0,1.5), 
     xlim = c(-6,10),
     main="OD-Ab.unit Non-linearity", pch=4) 
with(subset(std.raw, Specie=="Pviv"), 
     points(log(Ab.unit), mean.OD, col="blue", pch=4))
with(subset(std.raw, Specie=="Pfal"), 
     points(log(Ab.unit), mean.OD, col="red", pch=4))
legend("topleft", c("P.vivax","P.falcip"), #, "C+/-", "blank"
       col = c( "blue", "red"), #, "black", "black"
       pch = c(4, 4), #, NA, NA #lwd= c(1,1),
       #lty = c(NA, NA), #, 3, 2
       cex = 0.8,
       inset = .01#, merge = TRUE
)
### %CV
plot(cv.OD ~ mean.OD,std.raw, 
     ylim=c(0,100), xlim=c(0,1.5),
     xlab="mean OD 450nm of duplicates",
     ylab="%CV of duplicates",
     main="Percentage Coefficient of Variation")
abline(h=20, v=0.25, lty=2, col=2)
## SD
#plot(sd.OD ~ mean.OD,std.raw,
#     ylim = c(0,0.27),
#     main="Heteroskedasticity?") 
```

### Data filtering

```{r}
#mue # TOTAL MUESTRAS EVALUADAS
#rep # TOTAL INICIAL
#esp # TOTAL ESPERADO

##
# to FREEZE and ANALYSE
std.pre <- std.raw
#std.raw <- freeze
##
```

**`r mue` is the total amount of evaluated samples**. For each one, 02 read were made: 01 per specie. Before any filtering, the total amount of reads goes up to **`r rep` including replicates**. After filtering is applied, the **expected amount of left reads is `r esp`**.

A **function** called `checkIN()` would allow to evaluate the retrieving of replicated reads and addition of selected ones:

```{r}
#CHECK FUNCTION
checkIN <- function(a) {
  evalREP <- NULL
  for (i in 1:6) {
    evalREP <- c(evalREP, sum(table(a$ID)==i))
  }
  evalREP
}
```

First, replicates are retrieve:
```{r, eval=TRUE}
## RETRIEVE
dim(std.raw)[1]
checkIN(std.raw)
# triplicates
for (i in 1:length(as.character(triplOD))) {
  std.raw <- std.raw[std.raw$ID!=as.character(triplOD)[i],] # -96
}
checkIN(std.raw)
#dim(std.raw)[1]
# duplicates
for (i in 1:length(as.character(dupliOD))) {
  std.raw <- std.raw[std.raw$ID!=as.character(dupliOD)[i],] # -256
}
checkIN(std.raw)
#dim(std.raw)[1]

## NA
#std.raw <- std.raw[is.na(std.raw$Ab.unit)!=TRUE,] # -73
#checkIN(std.raw)
##
#dim(std.raw)[1]
#

# 3 muestras que pierden Pviv y Pfal por NaN en ambos Ab.unit
#((1772 - 1718) - 48)/2 == (length(NaN_2) -1)
##
```

Then, selected reads added:
```{r}
## ADDITION
# ADD NEW TRIPLICATES
std.raw <- rbind(std.raw,triplNEW) # + 32 = 16x2
checkIN(std.raw)
#dim(std.raw)
# ADD NEW DUPLICATES
std.raw <- rbind(std.raw,dupliNEW) # +128 + 1 = 64x2 + 1
checkIN(std.raw)
dim(std.raw)[1]
```

### Filtering evaluation

```{r}
std.nty <- std.raw
```

After filtering, we obtain **`r length(levels(std.nty$ID))` samples** of **`r mue` expected**, giving a **total of `r dim(std.nty)[1]` reads** on the data frame.

As seen in the last `checkIN`, **`r checkIN(std.raw)[1]` samples** have only one read because of **Ab.unit NaN**. For more detail, go to [Appendix C](#appendix-c-residual-na)

In addition, **`r (length(NaN_2) -1)` samples** were automatically retrieved as a consequence of **Ab.unit NaN** in both species reads. Look back to [NA description](#na).

### Plot after filtering
```{r pos-filter, fig.align='center', fig.height=3, fig.width=9}
summary(std.nty[,-c(1:2)])
par(mfrow=c(1,3))
### NON LINEAR RELATIONSHIP
plot(mean.OD ~ Ab.unit,std.nty,
     ylim = c(0,1.5), 
     xlim = c(0,5e3),
     main="OD-Ab.unit Non-linearity", pch=4) 
with(subset(std.nty, Specie=="Pviv"), 
     points(Ab.unit, mean.OD, col="blue", pch=4))
with(subset(std.nty, Specie=="Pfal"), 
     points(Ab.unit, mean.OD, col="red", pch=4))
legend("topright", c("P.vivax","P.falcip"), #, "C+/-", "blank"
       col = c( "blue", "red"), #, "black", "black"
       pch = c(4, 4), #, NA, NA #lwd= c(1,1),
       #lty = c(NA, NA), #, 3, 2
       cex = 0.8,
       inset = .01#, merge = TRUE
)
plot(mean.OD ~ log(Ab.unit),std.nty,
     ylim = c(0,1.5), 
     xlim = c(-6,10),
     main="OD-Ab.unit Non-linearity", pch=4) 
with(subset(std.nty, Specie=="Pviv"), 
     points(log(Ab.unit), mean.OD, col="blue", pch=4))
with(subset(std.nty, Specie=="Pfal"), 
     points(log(Ab.unit), mean.OD, col="red", pch=4))
legend("topleft", c("P.vivax","P.falcip"), #, "C+/-", "blank"
       col = c( "blue", "red"), #, "black", "black"
       pch = c(4, 4), #, NA, NA #lwd= c(1,1),
       #lty = c(NA, NA), #, 3, 2
       cex = 0.8,
       inset = .01#, merge = TRUE
)
### %CV
plot(cv.OD ~ mean.OD,std.nty, 
     ylim=c(0,100), xlim=c(0,1.5),
     xlab="mean OD 450nm of duplicates",
     ylab="%CV of duplicates",
     main="Percentage Coefficient of Variation")
abline(h=20, v=0.25, lty=2, col=2)
## SD
#plot(sd.OD ~ mean.OD,std.nty,
#     ylim = c(0,0.27),
#     main="Heteroskedasticity?") 
```



## DISTRIBUTIONS

### Linear scale

```{r linear-scale, fig.align='center', fig.height=6, fig.width=9}
### OD distribution
par(mfrow=c(2,3))

my <- max(hist(std.nty$mean.OD, plot = F)$counts, na.rm=TRUE)

hist(std.nty$mean.OD, xlim = c(0,1.4), 
     main = "mean.OD Histogram", xlab = "mean.OD")

hist(std.nty[std.nty$Specie=="Pviv",]$mean.OD, ylim = c(0,my), xlim = c(0,1.4), 
     main = "P.vivax", xlab = "mean.OD")

hist(std.nty[std.nty$Specie=="Pfal",]$mean.OD, ylim = c(0,my), xlim = c(0,1.4),
     main = "P.falciparum", xlab = "mean.OD")



### Ab distribution
#par(mfrow=c(1,3))

my <- max(hist(std.nty$Ab.unit, plot = F)$counts, na.rm=TRUE)

hist(std.nty$Ab.unit, 
     main = "Ab.units Histogram", xlab = "Ab.units")#, xlim = c(0,15000)

hist(std.nty[std.nty$Specie=="Pviv",]$Ab.unit, ylim = c(0,my),
     main = "P.vivax", xlab = "Ab.units")#, xlim = c(0,15000)

hist(std.nty[std.nty$Specie=="Pfal",]$Ab.unit, ylim = c(0,my),
     main = "P.falciparum", xlab = "Ab.units")#, xlim = c(0,15000)
```

### Log scale

```{r log-scale, fig.align='center', fig.height=6, fig.width=9}
par(mfrow=c(2,3))

my <- max(hist(log(std.nty$mean.OD), plot = F)$counts, na.rm=TRUE)

hist(log(std.nty$mean.OD), xlim = c(-3.5,1),
     main = "mean.OD Histogram", xlab = "log(mean.OD)")
hist(log(std.nty[std.nty$Specie=="Pviv",]$mean.OD), ylim = c(0,my), xlim = c(-3.5,1),
     main = "P.vivax", xlab = "log(mean.OD)")
hist(log(std.nty[std.nty$Specie=="Pfal",]$mean.OD), ylim = c(0,my), xlim = c(-3.5,1),
     main = "P.falciparum", xlab = "log(mean.OD)")

############
#par(mfrow=c(1,3))

my <- max(hist(log(std.nty$Ab.unit), plot = F)$counts, na.rm=TRUE)

hist(log(std.nty$Ab.unit), xlim = c(-6,10),
     main = "Ab.units Histogram", xlab = "log(Ab.units)")
hist(log(std.nty[std.nty$Specie=="Pviv",]$Ab.unit), ylim = c(0,my), xlim = c(-6,10),
     main = "P.vivax", xlab = "log(Ab.units)")
hist(log(std.nty[std.nty$Specie=="Pfal",]$Ab.unit), ylim = c(0,my), xlim = c(-6,10),
     main = "P.falciparum", xlab = "log(Ab.units)")
```

```{r, fig.align='center', fig.width=8, fig.height=3, eval=FALSE}
#library(ggplot2)
#library(Rmisc)        #multiploting ggplots
a <- ggplot(std.nty, aes(x=mean.OD, fill=Specie)) + 
  geom_histogram(alpha=.5, position = "identity") + 
  labs(title="Histograma de mean.OD") +
  scale_x_continuous(breaks = c(0,0.1,0.2,0.5,1,1.5),limits = c(0,1.5),
                     trans = "log1p", 
                     expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0),limits = c(0,600))
b <- ggplot(std.nty, aes(x=Ab.unit, fill=Specie)) + 
  geom_histogram(alpha=.5, position = "identity") + 
  labs(title="Histograma de Ab.units") +
  scale_x_continuous(breaks = c(0,1,10,100,1000,10000,20000), 
                     trans = "log1p", 
                     expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0),limits = c(0,600))
multiplot(a,b, cols = 2)
```


# EXPORT

## tidy format:

+ 01 row, 01 observation, 01 read

```{r}
#summary(std.nty[,-c(1:2)])
str(std.nty)
summary(std.nty)
```

## untidy format:

+ 01 row, 01 patient, 02 observations, 02 reads
+ done in a tidy-way.

```{r}
std.uty_ab <- std.nty %>% 
  tbl_df() %>% 
  select(ID, Ab.unit, Specie) %>% 
  spread(key = Specie, value = Ab.unit) %>% 
  dplyr::rename(id=ID,Ab.unit_Pfal=Pfal, Ab.unit_Pviv=Pviv)

std.uty_od <- std.nty %>% 
  tbl_df() %>% 
  select(ID, mean.OD, Specie) %>% 
  spread(key = Specie, value = mean.OD) %>% 
  dplyr::rename(id=ID,mean.OD_Pfal=Pfal, mean.OD_Pviv=Pviv)

std.uty <- full_join(std.uty_ab, std.uty_od, by="id")
str(std.uty)
summary(std.uty)
```

# save .Rds
```{r}
saveRDS(std.nty, "data/02-standard-tidy.rds")
saveRDS(std.uty, "data/02-standard-untidy.rds")

#saveRDS(std.nan, "data/02-out-of-bounce.rds")

#saveRDS(triplMAT, "data/02-triplicates.rds")
#saveRDS(dupliMAT, "data/02-duplicates.rds")
#saveRDS(triplNEW, "data/02-triplicates-filter.rds")
#saveRDS(dupliNEW, "data/02-duplicates-filter.rds")
```

***

# APPENDIX C: residual NA

TO DO:
    - Is it required to change NaN with 0 and NaN or .?
        + string replacement on Data.Filtering

- **67 samples** have OD below the lower limit:
- **04 samples** have OD above the upper limit:

```{r}
# a tibble of NaN only
std.nan <- std.raw %>% 
  filter(Ab.unit=="NaN") 

# tidy parameter tibble
std.par_t <- std.par %>% 
  gather(parSp, par.value, -Plate) %>% 
  separate(parSp,
           c("par","par.Specie"),
           sep="_")

# subset ones out by lower or upper limmit
std.out <- std.nan %>% 
  select(Plate, ID, Ab.unit, mean.OD, Specie) %>% 
  full_join(std.par_t,by = "Plate") %>% 
  filter(Specie == par.Specie) %>% 
  spread(par, par.value) %>% 
  mutate(out.low= c>mean.OD,
         out.upp= d<mean.OD) 

std.out %>% 
  filter(out.low==T)
std.out %>% 
  filter(out.upp==T)
```

- **10 samples** have NaN in both Pfal and Pviv:

```{r}
# NaN in both PFAL and PVIV ----> PRE filtering
std.nan %>% 
  count("ID") %>% 
  filter(freq > 1) %>% 
  inner_join(std.pre %>% 
               select(Plate, ID, Ab.unit, mean.OD, Specie)) %>% 
# NaN in both PFAL and PVIV ----> POS filtering
  #inner_join(std.nty)
  left_join(std.out)

```


# APPENDIX E: Replicates

## PRE selection

### pre triplicates
```{r}
triplMAT
```

### pre duplicates
```{r}
dupliMAT
```


## POST selection

### pos triplicates
```{r}
triplNEW
```

### pos duplicates
```{r}
dupliNEW
```


# References